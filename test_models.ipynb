{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from causal_inference.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>asian</th>\n",
       "      <th>black</th>\n",
       "      <th>hawaiian</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>unknown</th>\n",
       "      <th>white</th>\n",
       "      <th>format_ol</th>\n",
       "      <th>falsexam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.29997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.96000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>88.34996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  asian  black  hawaiian  hispanic  unknown  white  format_ol  \\\n",
       "0       0    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "1       1    0.0    0.0       0.0       0.0      0.0    1.0          0   \n",
       "4       1    0.0    0.0       0.0       0.0      0.0    1.0          1   \n",
       "5       0    1.0    0.0       0.0       0.0      0.0    0.0          1   \n",
       "7       1    1.0    0.0       0.0       0.0      0.0    0.0          0   \n",
       "\n",
       "   falsexam  \n",
       "0  63.29997  \n",
       "1  79.96000  \n",
       "4  83.30000  \n",
       "5  88.34996  \n",
       "7  90.00000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/course/online_classroom.csv')\n",
    "df = df[df.format_blended == 0].drop(columns=['format_blended',])\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>falsexam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>format_ol</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.779073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.383355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            falsexam\n",
       "format_ol           \n",
       "0          78.779073\n",
       "1          74.383355"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('format_ol').agg({'falsexam': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df.format_ol\n",
    "y = df.falsexam\n",
    "X = df.drop(columns=['falsexam', 'format_ol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: -4.396\n",
      "Confidence Interval: [-7.872, -0.920]\n"
     ]
    }
   ],
   "source": [
    "biased_model = BiasedModel()\n",
    "biased_model = biased_model.fit(T, y)\n",
    "ci_lower, ci_upper = biased_model.confidence_interval\n",
    "print(f'ATE: {biased_model.ate:.3f}')\n",
    "print(f'Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: -4.241\n",
      "Confidence Interval: [-7.745, -0.738]\n"
     ]
    }
   ],
   "source": [
    "linear_model = LinearModel()\n",
    "linear_model = linear_model.fit(X, T, y)\n",
    "ci_lower, ci_upper = linear_model.confidence_interval\n",
    "print(f'ATE: {linear_model.ate:.3f}')\n",
    "print(f'Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: -5.520\n",
      "Confidence Interval: [-9.467, 0.351]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNNModel()\n",
    "knn_model = knn_model.fit(X, T, y)\n",
    "ci_lower, ci_upper = knn_model.confidence_interval\n",
    "print(f'ATE: {knn_model.ate:.3f}')\n",
    "print(f'Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de propens√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: -4.300\n",
      "Confidence Interval: [-8.655, -0.901]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "propensity_model = PropensityModel(\n",
    "    LogisticRegression(),\n",
    ")\n",
    "propensity_model = propensity_model.fit(X, T, y)\n",
    "ci_lower, ci_upper = propensity_model.confidence_interval\n",
    "print(f'ATE: {propensity_model.ate:.3f}')\n",
    "print(f'Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doubly Robust Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: -4.064\n",
      "Confidence Interval: [-7.756, -0.522]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "dre_model = DoublyRobustEstimator(\n",
    "    LogisticRegression(), \n",
    ")\n",
    "dre_model = dre_model.fit(X, T, y)\n",
    "ci_lower, ci_upper = dre_model.confidence_interval\n",
    "print(f'ATE: {dre_model.ate:.3f}')\n",
    "print(f'Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual_inference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
